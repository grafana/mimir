{{- if .Values.ruler.kedaAutoscaling.enabled }}
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: {{ include "mimir.resourceName" (dict "ctx" . "component" "ruler") }}
  labels:
    {{- include "mimir.labels" (dict "ctx" . "component" "ruler") | nindent 4 }}
  annotations:
    {{- toYaml .Values.ruler.annotations | nindent 4 }}
  namespace: {{ .Release.Namespace | quote }}
spec:
  advanced:
    horizontalPodAutoscalerConfig:
      {{- with .Values.ruler.kedaAutoscaling.behavior }}
      behavior:
        {{- toYaml . | nindent 8 }}
      {{- end }}
  maxReplicaCount: {{ .Values.ruler.kedaAutoscaling.maxReplicaCount }}
  minReplicaCount: {{ .Values.ruler.kedaAutoscaling.minReplicaCount }}
  pollingInterval: {{ .Values.kedaAutoscaling.pollingInterval }}
  scaleTargetRef:
    name: {{ include "mimir.resourceName" (dict "ctx" . "component" "ruler") }}
    apiVersion: apps/v1
    kind: Deployment
  triggers:
  - metadata:
      query: max_over_time(sum(sum by (pod) (rate(container_cpu_usage_seconds_total{container="ruler",namespace="{{ .Release.Namespace }}"}[5m])) and max by (pod) (up{container="ruler",namespace="{{ .Release.Namespace }}"}) > 0)[15m:]) * 1000
      serverAddress: {{ include "mimir.kedaPrometheusAddress" (dict "ctx" $) }} 
      {{- $cpu_request := dig "requests" "cpu" nil .Values.ruler.resources }}
      threshold: {{ mulf (include "mimir.cpuToMilliCPU" (dict "value" $cpu_request)) (divf .Values.ruler.kedaAutoscaling.targetCPUUtilizationPercentage 100) | floor | int64 | quote }}
      {{- if .Values.kedaAutoscaling.customHeaders }}
      customHeaders: {{ (include "mimir.lib.mapToCSVString" (dict "map" .Values.kedaAutoscaling.customHeaders)) | quote }}
      {{- end }}
    type: prometheus
  - metadata:
      query: max_over_time(sum((sum by (pod) (container_memory_working_set_bytes{container="ruler",namespace="{{ .Release.Namespace }}"}) and max by (pod) (up{container="ruler",namespace="{{ .Release.Namespace }}"}) > 0) or vector(0))[15m:]) + sum(sum by (pod) (max_over_time(kube_pod_container_resource_requests{container="ruler",namespace="{{ .Release.Namespace }}", resource="memory"}[15m])) and max by (pod) (changes(kube_pod_container_status_restarts_total{container="ruler",namespace="{{ .Release.Namespace }}"}[15m]) > 0) and max by (pod) (kube_pod_container_status_last_terminated_reason{container="ruler",namespace="{{ .Release.Namespace }}", reason="OOMKilled"}) or vector(0))
      serverAddress: {{ include "mimir.kedaPrometheusAddress" (dict "ctx" $) }} 
      {{- $mem_request := dig "requests" "memory" nil .Values.ruler.resources }}
      threshold: {{ mulf (include "mimir.siToBytes" (dict "value" $mem_request)) (divf .Values.ruler.kedaAutoscaling.targetMemoryUtilizationPercentage 100) | floor | int64 | quote }}
      {{- if .Values.kedaAutoscaling.customHeaders }}
      customHeaders: {{ (include "mimir.lib.mapToCSVString" (dict "map" .Values.kedaAutoscaling.customHeaders)) | quote }}
      {{- end }}
    type: prometheus
{{- end }}