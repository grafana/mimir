# Grafana Enterprise Metrics specific values and features are found after the `enterprise:` key
#
# The default values specified in this file are enough to deploy all of the
# Grafana Mimir or Grafana Enterprise Metrics microservices but are not suitable for
# production load.
# To configure the resources for production load, refer to the the small.yaml or
# large.yaml values files.

# -- Overrides the chart's name. Used to change mimir/enterprise-metrics infix in the resource names. E.g. myRelease-mimir-ingester-1 to myRelease-nameOverride-ingester-1.
# This option is used to align resource names with Cortex, when doing a migration from Cortex to Grafana Mimir.
# Note: Grafana provided dashboards rely on the default naming and will need changes.
nameOverride: null

# -- Overrides the chart's computed fullname. Used to change the full prefix of resource names. E.g. myRelease-mimir-ingester-1 to fullnameOverride-ingester-1.
# Note: Grafana provided dashboards rely on the default naming and will need changes.
fullnameOverride: null

# Container image settings.
# Since the image is unique for all microservices, so are image settings.
image:
  repository: grafana/mimir
  tag: r191-e11ac85
  pullPolicy: IfNotPresent
  # Optionally specify an array of imagePullSecrets.
  # Secrets must be manually created in the namespace.
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
  # pullSecrets:
  #   - myRegistryKeySecretName

global:
  # -- Definitions to set up nginx resolver
  dnsService: kube-dns
  dnsNamespace: kube-system
  clusterDomain: cluster.local

  # -- Common environment variables to add to all pods directly managed by this chart.
  # scope: admin-api, alertmanager, compactor, distributor, gateway, ingester, nginx, overrides-exporter, querier, query-frontend, ruler, store-gateway, tokengen
  extraEnv: []

  # -- Common source of environment injections to add to all pods directly managed by this chart.
  # scope: admin-api, alertmanager, compactor, distributor, gateway, ingester, nginx, overrides-exporter, querier, query-frontend, ruler, store-gateway, tokengen
  # For example to inject values from a Secret, use:
  # extraEnvFrom:
  #   - secretRef:
  #       name: mysecret
  extraEnvFrom: []

  # -- Pod annotations for all pods directly managed by this chart. Usable for example to associate a version to 'global.extraEnv' and 'global.extraEnvFrom' and trigger a restart of the affected services.
  # scope: admin-api, alertmanager, compactor, distributor, gateway, ingester, nginx, overrides-exporter, querier, query-frontend, ruler, store-gateway, tokengen
  podAnnotations: {}

serviceAccount:
  create: true
  name:
  annotations: {}

# -- Configuration is loaded from the secret called 'externalConfigSecretName'. If 'useExternalConfig' is true, then the configuration is not generated, just consumed.
useExternalConfig: false

# -- Defines what kind of object stores the configuration, a ConfigMap or a Secret.
# In order to move sensitive information (such as credentials) from the ConfigMap/Secret to a more secure location (e.g. vault), it is possible to use [environment variables in the configuration](https://grafana.com/docs/mimir/latest/operators-guide/configuring/reference-configuration-parameters/#use-environment-variables-in-the-configuration).
# Such environment variables can be then stored in a separate Secret and injected via the global.extraEnvFrom value. For details about environment injection from a Secret please see [Secrets](https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables).
configStorageType: Secret

# -- Name of the Secret or ConfigMap that contains the configuration (used for naming even if config is internal).
externalConfigSecretName: '{{ include "mimir.resourceName" (dict "ctx" . "component" "config") }}'

# -- When 'useExternalConfig' is true, then changing 'externalConfigVersion' triggers restart of services - otherwise changes to the configuration cause a restart.
externalConfigVersion: '0'

mimir:
  # -- Base config file for Grafana Mimir and Grafana Enterprise Metrics. Contains Helm templates that are evaulated at install/upgrade.
  # To modify the resulting configuration, either copy and alter 'mimir.config' as a whole or use the 'mimir.structuredConfig' to add and modify certain YAML elements.
  config: |
    activity_tracker:
      filepath: /data/metrics-activity.log

    {{- if .Values.enterprise.enabled }}
    admin_api:
      leader_election:
        enabled: true
        ring:
          kvstore:
            store: "memberlist"

      {{- if .Values.minio.enabled }}
    admin_client:
      storage:
        type: s3
        s3:
          access_key_id: {{ .Values.minio.accessKey }}
          bucket_name: enterprise-metrics-admin
          endpoint: {{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000
          insecure: true
          secret_access_key: {{ .Values.minio.secretKey }}
      {{- end }}
    {{- end }}

    alertmanager:
      data_dir: /data
      enable_api: true
      external_url: /alertmanager

    {{- if .Values.minio.enabled }}
    alertmanager_storage:
      backend: s3
      s3:
        access_key_id: {{ .Values.minio.accessKey }}
        bucket_name: {{ include "mimir.minioBucketPrefix" . }}-ruler
        endpoint: {{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000
        insecure: true
        secret_access_key: {{ .Values.minio.secretKey }}
    {{- end }}

    {{- if .Values.enterprise.enabled }}
    auth:
      type: enterprise
    {{- end }}

    # This configures how the store-gateway synchronizes blocks stored in the bucket. It uses Minio by default for getting started (configured via flags) but this should be changed for production deployments.
    blocks_storage:
      backend: s3
      bucket_store:
        {{- if index .Values "memcached-chunks" "enabled" }}
        chunks_cache:
          backend: memcached
          memcached:
            addresses: dns+{{ template "mimir.fullname" . }}-memcached-chunks.{{ .Release.Namespace }}.svc:{{ (index .Values "memcached-chunks").port }}
            max_item_size: {{ mul (index .Values "memcached-chunks").maxItemMemory 1024 1024 }}
            timeout: 450ms
        {{- end }}
        {{- if index .Values "memcached-index-queries" "enabled" }}
        index_cache:
          backend: memcached
          memcached:
            addresses: dns+{{ template "mimir.fullname" . }}-memcached-index-queries.{{ .Release.Namespace }}.svc:{{ (index .Values "memcached-index-queries").port }}
            max_item_size: {{ mul (index .Values "memcached-index-queries").maxItemMemory 1024 1024 }}
        {{- end }}
        {{- if index .Values "memcached-metadata" "enabled" }}
        metadata_cache:
          backend: memcached
          memcached:
            addresses: dns+{{ template "mimir.fullname" . }}-memcached-metadata.{{ .Release.Namespace }}.svc:{{ (index .Values "memcached-metadata").port }}
            max_item_size: {{ mul (index .Values "memcached-metadata").maxItemMemory 1024 1024 }}
        {{- end }}
        sync_dir: /data/tsdb-sync
      {{- if .Values.minio.enabled }}
      s3:
        access_key_id: {{ .Values.minio.accessKey }}
        bucket_name: {{ include "mimir.minioBucketPrefix" . }}-tsdb
        endpoint: {{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000
        insecure: true
        secret_access_key: {{ .Values.minio.secretKey }}
      {{- end }}
      tsdb:
        dir: /data/tsdb

    {{- if .Values.enterprise.enabled }}
    cluster_name: "{{ .Release.Name }}"
    {{- end }}

    compactor:
      data_dir: "/data"

    frontend:
      align_queries_with_step: true
      log_queries_longer_than: 10s
      {{- if index .Values "memcached-results" "enabled" }}
      results_cache:
        backend: memcached
        memcached:
          addresses: dns+{{ template "mimir.fullname" . }}-memcached-results.{{ .Release.Namespace }}.svc:{{ (index .Values "memcached-results").port }}
          max_item_size: {{ mul (index .Values "memcached-results").maxItemMemory 1024 1024 }}
      cache_results: true
      {{- end }}

    frontend_worker:
      frontend_address: {{ template "mimir.fullname" . }}-query-frontend-headless.{{ .Release.Namespace }}.svc:{{ include "mimir.serverGrpcListenPort" . }}

    {{- if and .Values.enterprise.enabled .Values.gateway.useDefaultProxyURLs }}
    gateway:
      proxy:
        admin_api:
          url: http://{{ template "mimir.fullname" . }}-admin-api.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        alertmanager:
          url: http://{{ template "mimir.fullname" . }}-alertmanager.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        compactor:
          url: http://{{ template "mimir.fullname" . }}-compactor.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        default:
          url: http://{{ template "mimir.fullname" . }}-admin-api.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        distributor:
          url: dns:///{{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverGrpcListenPort" . }}
        ingester:
          url: http://{{ template "mimir.fullname" . }}-ingester.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        query_frontend:
          url: http://{{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        ruler:
          url: http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
        store_gateway:
          url: http://{{ template "mimir.fullname" . }}-store-gateway.{{ .Release.Namespace }}.svc:{{ include "mimir.serverHttpListenPort" . }}
    {{- end }}

    ingester:
      ring:
        final_sleep: 0s
        num_tokens: 512
        unregister_on_shutdown: false

    ingester_client:
      grpc_client_config:
        max_recv_msg_size: 104857600
        max_send_msg_size: 104857600

    {{- if .Values.enterprise.enabled }}
    instrumentation:
      enabled: true
      distributor_client:
        address: dns:///{{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverGrpcListenPort" . }}

    license:
      path: "/license/license.jwt"
    {{- end }}

    limits: {}

    memberlist:
      abort_if_cluster_join_fails: false
      compression_enabled: false
      join_members:
      - {{ include "mimir.fullname" . }}-gossip-ring

    ruler:
      alertmanager_url: dnssrvnoa+http://_http-metrics._tcp.{{ template "mimir.fullname" . }}-alertmanager-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}/alertmanager
      enable_api: true
      rule_path: /data

    {{- if .Values.minio.enabled }}
    ruler_storage:
      backend: s3
      s3:
        endpoint: {{ .Release.Name }}-minio.{{ .Release.Namespace }}.svc:9000
        bucket_name: {{ include "mimir.minioBucketPrefix" . }}-ruler
        access_key_id: {{ .Values.minio.accessKey }}
        secret_access_key: {{ .Values.minio.secretKey }}
        insecure: true
    {{- end }}

    runtime_config:
      file: /var/{{ include "mimir.name" . }}/runtime.yaml

    server:
      grpc_server_max_recv_msg_size: 104857600
      grpc_server_max_send_msg_size: 104857600
      grpc_server_max_concurrent_streams: 1000

  # -- Additional structured values on top of the text based 'mimir.config'. Applied after the text based config is evaulated for templates. Enables adding and modifying YAML elements in the evaulated 'mimir.config'.
  structuredConfig: {}

# runtimeConfig provides a reloadable runtime configuration file for some specific configuration.
runtimeConfig: {}

# RBAC configuration
rbac:
  pspEnabled: true

# ServiceMonitor configuration
serviceMonitor:
  # -- If enabled, ServiceMonitor resources for Prometheus Operator are created
  enabled: false
  # -- To disable setting a 'cluster' label in metrics, set to 'null'.
  # To overwrite the 'cluster' label with your own value, set to a non-empty string.
  # Keep empty string "" to have the default value in the 'cluster' label, which is the helm release name for Mimir and the actual cluster name for Enterprise Metrics.
  clusterLabel: ""
  # -- Alternative namespace for ServiceMonitor resources
  # If left unset, the default is to install the ServiceMonitor resources in the namespace where the chart is installed, i.e. the namespace specified for the helm command.
  namespace: null
  # -- Namespace selector for ServiceMonitor resources
  # If left unset, the default is to select the namespace where the chart is installed, i.e. the namespace specified for the helm command.
  namespaceSelector: null
  # -- ServiceMonitor annotations
  annotations: {}
  # -- Additional ServiceMonitor labels
  labels: {}
  # -- ServiceMonitor scrape interval
  interval: null
  # -- ServiceMonitor scrape timeout in Go duration format (e.g. 15s)
  scrapeTimeout: null
  # -- ServiceMonitor relabel configs to apply to samples before scraping
  # https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
  relabelings: []
  # -- ServiceMonitor will use http by default, but you can pick https as well
  scheme: http
  # -- ServiceMonitor will use these tlsConfig settings to make the health check requests
  tlsConfig: null

alertmanager:
  enabled: true
  replicas: 1

  statefulSet:
    enabled: true

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 10m
      memory: 32Mi

  extraArgs: {}

  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity: {}
  annotations: {}
  persistence:
    # SubPath in emptyDir for persistence, only enabled if alertmanager.statefulSet.enabled is false
    subPath:

  persistentVolume:
    # If true and alertmanager.statefulSet.enabled is true,
    # Alertmanager will create/use a Persistent Volume Claim
    # If false, use emptyDir
    enabled: true

    # Alertmanager data Persistent Volume Claim annotations
    #
    annotations: {}

    # Alertmanager data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    #
    accessModes:
      - ReadWriteOnce

    # Alertmanager data Persistent Volume size
    #
    size: 1Gi

    # Subdirectory of Alertmanager data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    #
    subPath: ''

    # Alertmanager data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    #   set, choosing the default provisioner.  (gp2 on AWS, standard on
    #   GKE, AWS & OpenStack)
    #
    # storageClass: "-"

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  securityContext: {}

  # Tolerations for pod assignment
  # ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  statefulStrategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 60

  initContainers: []
  # Init containers to be added to the alertmanager pod.
  # - name: my-init-container
  #   image: busybox:latest
  #   command: ['sh', '-c', 'echo hello']

  extraContainers: []
  # Additional containers to be added to the alertmanager pod.
  # - name: reverse-proxy
  #   image: angelbarrera92/basic-auth-reverse-proxy:dev
  #   args:
  #     - "serve"
  #     - "--upstream=http://localhost:3100"
  #     - "--auth-config=/etc/reverse-proxy-conf/authn.yaml"
  #   ports:
  #     - name: http
  #       containerPort: 11811
  #       protocol: TCP
  #   volumeMounts:
  #     - name: reverse-proxy-auth-config
  #       mountPath: /etc/reverse-proxy-conf

  extraVolumes: []
  # Additional volumes to the alertmanager pod.
  # - name: reverse-proxy-auth-config
  #   secret:
  #     secretName: reverse-proxy-auth-config

  # Extra volume mounts that will be added to the alertmanager container
  extraVolumeMounts: []

  # Extra env variables to pass to the alertmanager container
  env: []
  extraEnvFrom: []

distributor:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 512Mi

  # Additional distributor container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}

  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: target
                operator: In
                values:
                  - distributor
          topologyKey: 'kubernetes.io/hostname'

  annotations: {}
  persistence:
    subPath:

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  securityContext: {}

  # -- The SecurityContext for distributor containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 60

  tolerations: []
  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

ingester:
  replicas: 3

  statefulSet:
    enabled: true

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 512Mi

  # Additional ingester container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}
  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget:
    maxUnavailable: 1

  podManagementPolicy: Parallel

  nodeSelector: {}
  affinity: {}
  annotations: {}

  persistentVolume:
    # If true and ingester.statefulSet.enabled is true,
    # Ingester will create/use a Persistent Volume Claim
    # If false, use emptyDir
    #
    enabled: true

    # Ingester data Persistent Volume Claim annotations
    #
    annotations: {}

    # Ingester data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    accessModes:
      - ReadWriteOnce

    # Ingester data Persistent Volume size
    size: 2Gi

    # Subdirectory of Ingester data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    subPath: ''


    # Ingester data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    #   set, choosing the default provisioner.  (gp2 on AWS, standard on
    #   GKE, AWS & OpenStack)
    #
    # storageClass: "-"

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 60

  securityContext: {}

  # -- The SecurityContext for ingester containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  statefulStrategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 240

  tolerations: []
  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

overrides_exporter:
  enabled: true
  replicas: 1

  annotations: {}

  initContainers: []

  service:
    annotations: {}
    labels: {}

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  podLabels: {}
  podAnnotations: {}
  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity: {}

  securityContext: {}

   # -- The SecurityContext for overrides_exporter containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  extraArgs: {}

  persistence:
    subPath:

  livenessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45
  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  resources:
    requests:
      cpu: 100m
      memory: 128Mi

  terminationGracePeriodSeconds: 60

  tolerations: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

ruler:
  enabled: true
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 128Mi

  # Additional ruler container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}
    # log.level: debug

  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity: {}
  annotations: {}
  persistence:
    subPath:

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  securityContext: {}

  # -- The SecurityContext for ruler containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []
  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

querier:
  replicas: 2

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 128Mi

  # Additional querier container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}

  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: target
                  operator: In
                  values:
                    - querier
            topologyKey: 'kubernetes.io/hostname'

  annotations: {}
  persistence:
    subPath:

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  securityContext: {}

  # -- The SecurityContext for querier containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []
  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

query_frontend:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 128Mi

  # Additional query-frontend container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}

  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: target
                  operator: In
                  values:
                    - query-frontend
            topologyKey: 'kubernetes.io/hostname'

  annotations: {}
  persistence:
    subPath:

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  securityContext: {}

  # -- The SecurityContext for query_frontend containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  terminationGracePeriodSeconds: 180

  tolerations: []
  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

store_gateway:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 512Mi

  # Additional store-gateway container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}

  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget:
    maxUnavailable: 1

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: target
                operator: In
                values:
                  - store-gateway
          topologyKey: 'kubernetes.io/hostname'

  annotations: {}

  persistentVolume:
    # If true Store-gateway will create/use a Persistent Volume Claim
    # If false, use emptyDir
    #
    enabled: true

    # Store-gateway data Persistent Volume Claim annotations
    #
    annotations: {}

    # Store-gateway data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    #
    accessModes:
      - ReadWriteOnce

    # Store-gateway data Persistent Volume size
    #
    size: 2Gi

    # Subdirectory of Store-gateway data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    #
    subPath: ''


    # Store-gateway data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    #   set, choosing the default provisioner.  (gp2 on AWS, standard on
    #   GKE, AWS & OpenStack)
    #
    # storageClass: "-"

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 60

  securityContext: {}

   # -- The SecurityContext for store_gateway containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 240

  tolerations: []
  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

compactor:
  replicas: 1

  service:
    annotations: {}
    labels: {}

  resources:
    requests:
      cpu: 100m
      memory: 512Mi

  # Additional compactor container arguments, e.g. log level (debug, info, warn, error)
  extraArgs: {}

  # Pod Labels
  podLabels: {}

  # Pod Annotations
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: target
                  operator: In
                  values:
                    - compactor
            topologyKey: 'kubernetes.io/hostname'

  annotations: {}

  persistentVolume:
    # If true compactor will create/use a Persistent Volume Claim
    # If false, use emptyDir
    #
    enabled: true

    # compactor data Persistent Volume Claim annotations
    #
    annotations: {}

    # compactor data Persistent Volume access modes
    # Must match those of existing PV or dynamic provisioner
    # Ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    #
    accessModes:
      - ReadWriteOnce

    # compactor data Persistent Volume size
    #
    size: 2Gi

    # Subdirectory of compactor data Persistent Volume to mount
    # Useful if the volume's root directory is not empty
    #
    subPath: ''

    # compactor data Persistent Volume Storage Class
    # If defined, storageClassName: <storageClass>
    # If set to "-", storageClassName: "", which disables dynamic provisioning
    # If undefined (the default) or set to null, no storageClassName spec is
    #   set, choosing the default provisioner.  (gp2 on AWS, standard on
    #   GKE, AWS & OpenStack)
    #
    # storageClass: "-"

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 60

  securityContext: {}

  # -- The SecurityContext for compactor containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  strategy:
    type: RollingUpdate

  terminationGracePeriodSeconds: 240

  tolerations: []
  initContainers: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

memcached:
  image:
    # -- Memcached Docker image repository
    repository: memcached
    # -- Memcached Docker image tag
    tag: 1.6.9-alpine
    # -- Memcached Docker image pull policy
    pullPolicy: IfNotPresent

  # -- The SecurityContext for memcached pods
  podSecurityContext:
    fsGroup: 11211
    runAsGroup: 11211
    runAsNonRoot: true
    runAsUser: 11211

  # -- The SecurityContext for memcached containers
  containerSecurityContext:
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    allowPrivilegeEscalation: false

memcachedExporter:
  # -- Whether memcached metrics should be exported
  enabled: true

  image:
    repository: prom/memcached-exporter
    tag: v0.6.0
    pullPolicy: IfNotPresent

memcached-chunks:
  # -- Specifies whether memcached-chunks should be enabled
  enabled: false

  # -- Total number of memcached-chunks replicas
  replicas: 1

  # -- Port of the memcached-chunks service
  port: 11211

  # -- Amount of memory allocated to memcached-chunks for object storage (in MB).
  allocatedMemory: 8192

  # -- Maximum item memory for memcached-chunks (in MB).
  maxItemMemory: 1

  # -- Extra init containers for memcached-chunks pods
  initContainers: []

  # -- Annotations for the memcached-chunks pods
  annotations: {}
  # -- Node selector for memcached-chunks pods
  nodeSelector: {}
  # -- Affinity for memcached-chunks pods
  affinity: {}
  # -- Tolerations for memcached-chunks pods
  tolerations: []
  # -- Pod Disruption Budget
  podDisruptionBudget: {}
  # -- The name of the PriorityClass for memcached-chunks pods
  priorityClassName: null
  # -- Labels for memcached-chunks pods
  podLabels: {}
  # -- Annotations for memcached-chunks pods
  podAnnotations: {}
  # -- Management policy for memcached-chunks pods
  podManagementPolicy: Parallel
  # -- Grace period to allow the memcached-chunks to shutdown before it is killed
  terminationGracePeriodSeconds: 60

  # -- Stateful memcached-chunks strategy
  statefulStrategy:
    type: RollingUpdate

  # -- Additional CLI args for memcached-chunks
  extraArgs: []

  # -- Additional containers to be added to the memcached-chunks pod.
  extraContainers: []

  # -- Resource requests and limits for the memcached-results
  # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
  resources: null

  # -- Service annotations and labels
  service:
    annotations: {}
    labels: {}

memcached-index-queries:
  # -- Specifies whether memcached-index-queries should be enabled
  enabled: false

  # -- Total number of memcached-index-queries replicas
  replicas: 1

  # -- Port of the memcached-index-queries service
  port: 11211

  # -- Amount of memory allocated to memcached-index-queries for object storage (in MB).
  allocatedMemory: 2048

  # -- Maximum item memcached-index-queries for memcached (in MB).
  maxItemMemory: 15

  # -- Extra init containers for memcached-index-queries pods
  initContainers: []

  # -- Annotations for the memcached-index-queries pods
  annotations: {}
  # -- Node selector for memcached-index-queries pods
  nodeSelector: {}
  # -- Affinity for memcached-index-queries pods
  affinity: {}
  # -- Tolerations for memcached-index-queries pods
  tolerations: []
  # -- Pod Disruption Budget
  podDisruptionBudget: {}
  # -- The name of the PriorityClass for memcached-index-queries pods
  priorityClassName: null
  # -- Labels for memcached-index-queries pods
  podLabels: {}
  # -- Annotations for memcached-index-queries pods
  podAnnotations: {}
  # -- Management policy for memcached-index-queries pods
  podManagementPolicy: Parallel
  # -- Grace period to allow the memcached-index-queries to shutdown before it is killed
  terminationGracePeriodSeconds: 60

  # -- Stateful memcached-index-queries strategy
  statefulStrategy:
    type: RollingUpdate

  # -- Additional CLI args for memcached-index-queries
  extraArgs: []

  # -- Additional containers to be added to the memcached-index-queries pod.
  extraContainers: []

  # -- Resource requests and limits for the memcached-results
  # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
  resources: null

  # -- Service annotations and labels
  service:
    annotations: {}
    labels: {}

memcached-metadata:
  # -- Specifies whether memcached-metadata should be enabled
  enabled: false

  # -- Total number of memcached-metadata replicas
  replicas: 1

  # -- Port of the memcached-metadata service
  port: 11211

  # -- Amount of memory allocated to memcached-metadata for object storage (in MB).
  allocatedMemory: 512

  # -- Maximum item memcached-metadata for memcached (in MB).
  maxItemMemory: 1

  # -- Extra init containers for memcached-metadata pods
  initContainers: []

  # -- Annotations for the memcached-metadata pods
  annotations: {}
  # -- Node selector for memcached-metadata pods
  nodeSelector: {}
  # -- Affinity for memcached-metadata pods
  affinity: {}
  # -- Tolerations for memcached-metadata pods
  tolerations: []
  # -- Pod Disruption Budget
  podDisruptionBudget: {}
  # -- The name of the PriorityClass for memcached-metadata pods
  priorityClassName: null
  # -- Labels for memcached-metadata pods
  podLabels: {}
  # -- Annotations for memcached-metadata pods
  podAnnotations: {}
  # -- Management policy for memcached-metadata pods
  podManagementPolicy: Parallel
  # -- Grace period to allow the memcached-metadata to shutdown before it is killed
  terminationGracePeriodSeconds: 60

  # -- Stateful memcached-metadata strategy
  statefulStrategy:
    type: RollingUpdate

  # -- Additional CLI args for memcached-metadata
  extraArgs: []

  # -- Additional containers to be added to the memcached-metadata pod.
  extraContainers: []

  # -- Resource requests and limits for the memcached-results
  # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
  resources: null

  # -- Service annotations and labels
  service:
    annotations: {}
    labels: {}

memcached-results:
  # -- Specifies whether memcached-results should be enabled
  enabled: false

  # -- Total number of memcached-results replicas
  replicas: 1

  # -- Port of the memcached-results service
  port: 11211

  # -- Amount of memory allocated to memcached-results for object storage (in MB).
  allocatedMemory: 512

  # -- Maximum item memcached-results for memcached (in MB).
  maxItemMemory: 1

  # -- Extra init containers for memcached-results pods
  initContainers: []

  # -- Annotations for the memcached-results pods
  annotations: {}
  # -- Node selector for memcached-results pods
  nodeSelector: {}
  # -- Affinity for memcached-results pods
  affinity: {}
  # -- Tolerations for memcached-results pods
  tolerations: []
  # -- Pod Disruption Budget
  podDisruptionBudget: {}
  # -- The name of the PriorityClass for memcached-results pods
  priorityClassName: null
  # -- Labels for memcached-results pods
  podLabels: {}
  # -- Annotations for memcached-results pods
  podAnnotations: {}
  # -- Management policy for memcached-results pods
  podManagementPolicy: Parallel
  # -- Grace period to allow the memcached-results to shutdown before it is killed
  terminationGracePeriodSeconds: 60

  # -- Stateful memcached-results strategy
  statefulStrategy:
    type: RollingUpdate

  # -- Additional CLI args for memcached-results
  extraArgs: []

  # -- Additional containers to be added to the memcached-results pod.
  extraContainers: []

  # -- Resource requests and limits for the memcached-results
  # By default a safe memory limit will be requested based on allocatedMemory value (floor (* 1.2 allocatedMemory)).
  resources: null

  # -- Service annotations and labels
  service:
    annotations: {}
    labels: {}

minio:
  enabled: true
  accessKey: grafana-mimir
  buckets:
    - name: mimir-tsdb
      policy: none
      purge: false
    - name: mimir-ruler
      policy: none
      purge: false
    - name: enterprise-metrics-tsdb
      policy: none
      purge: false
    - name: enterprise-metrics-admin
      policy: none
      purge: false
    - name: enterprise-metrics-ruler
      policy: none
      purge: false
  persistence:
    size: 5Gi
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
  secretKey: supersecret

# Configuration for nginx gateway
nginx:
  # -- Specifies whether nginx should be enabled
  enabled: true
  # -- Number of replicas for nginx
  replicas: 1
  # -- Enable logging of 2xx and 3xx HTTP requests
  verboseLogging: true
  autoscaling:
    # -- Enable autoscaling for nginx
    enabled: false
    # -- Minimum autoscaling replicas for nginx
    minReplicas: 1
    # -- Maximum autoscaling replicas for nginx
    maxReplicas: 3
    # -- Target CPU utilisation percentage for nginx
    targetCPUUtilizationPercentage: 60
    # -- Target memory utilisation percentage for nginx
    targetMemoryUtilizationPercentage:
  # -- See `kubectl explain deployment.spec.strategy` for more,
  # ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  deploymentStrategy:
    type: RollingUpdate
  image:
    # -- The Docker registry for nginx image
    registry: docker.io
    # -- The nginx image repository
    repository: nginxinc/nginx-unprivileged
    # -- The nginx image tag
    tag: 1.19-alpine
    # -- The nginx image pull policy
    pullPolicy: IfNotPresent
  # -- The name of the PriorityClass for nginx pods
  priorityClassName: null
  # -- Labels for nginx pods
  podLabels: {}
  # -- Annotations for nginx pods
  podAnnotations: {}
  # -- Pod Disruption Budget
  podDisruptionBudget: {}
  # -- Additional CLI args for nginx
  extraArgs: []
  # -- Environment variables to add to the nginx pods
  extraEnv: []
  # -- Environment variables from secrets or configmaps to add to the nginx pods
  extraEnvFrom: []
  # -- Volumes to add to the nginx pods
  extraVolumes: []
  # -- Volume mounts to add to the nginx pods
  extraVolumeMounts: []
  # -- The SecurityContext for nginx containers
  podSecurityContext:
    fsGroup: 101
    runAsGroup: 101
    runAsNonRoot: true
    runAsUser: 101
  # -- The SecurityContext for nginx containers
  containerSecurityContext:
    readOnlyRootFilesystem: true
    capabilities:
      drop:
        - ALL
    allowPrivilegeEscalation: false
  # -- Resource requests and limits for the nginx
  resources: {}
  # -- Grace period to allow the nginx to shutdown before it is killed
  terminationGracePeriodSeconds: 30
  # -- Affinity for nginx pods. Passed through `tpl` and, thus, to be configured as string
  # @default -- Hard node and soft zone anti-affinity
  affinity: |
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: component
                  operator: In
                  values:
                    - nginx
            topologyKey: failure-domain.beta.kubernetes.io/zone

  annotations: {}

  # -- Node selector for nginx pods
  nodeSelector: {}
  # -- Tolerations for nginx pods
  tolerations: []
  # Nginx service configuration
  service:
    # -- Port of the nginx service
    port: 80
    # -- Type of the nginx service
    type: ClusterIP
    # -- ClusterIP of the nginx service
    clusterIP: null
    # -- Node port if service type is NodePort
    nodePort: null
    # -- Load balancer IPO address if service type is LoadBalancer
    loadBalancerIP: null
    # -- Annotations for the nginx service
    annotations: {}
    # -- Labels for nginx service
    labels: {}
  # Ingress configuration
  ingress:
    # -- Specifies whether an ingress for the nginx should be created
    enabled: false
    # -- Ingress Class Name. MAY be required for Kubernetes versions >= 1.18
    # ingressClassName: nginx
    # -- Annotations for the nginx ingress
    annotations: {}
    # -- Hosts configuration for the nginx ingress
    hosts:
      - host: nginx.loki.example.com
        paths:
          - path: /
            # -- pathType (e.g. ImplementationSpecific, Prefix, .. etc.) might also be required by some Ingress Controllers
            # pathType: Prefix
    # -- TLS configuration for the nginx ingress
    tls:
      - secretName: loki-nginx-tls
        hosts:
          - nginx.loki.example.com
  # Basic auth configuration
  basicAuth:
    # -- Enables basic authentication for nginx
    enabled: false
    # -- The basic auth username for nginx
    username: null
    # -- The basic auth password for nginx
    password: null
    # -- Uses the specified username and password to compute a htpasswd using Sprig's `htpasswd` function.
    # The value is templated using `tpl`. Override this to use a custom htpasswd, e.g. in case the default causes
    # high CPU load.
    htpasswd: >-
      {{ htpasswd (required "'nginx.basicAuth.username' is required" .Values.nginx.basicAuth.username) (required "'nginx.basicAuth.password' is required" .Values.nginx.basicAuth.password) }}
    # -- Existing basic auth secret to use. Must contain '.htpasswd'
    existingSecret: null
  # Configures the readiness probe for nginx
  readinessProbe:
    httpGet:
      path: /
      port: http-metric
    initialDelaySeconds: 15
    timeoutSeconds: 1
  nginxConfig:
    # -- NGINX log format
    logFormat: |-
      main '$remote_addr - $remote_user [$time_local]  $status '
              '"$request" $body_bytes_sent "$http_referer" '
              '"$http_user_agent" "$http_x_forwarded_for"';
    # -- Allows appending custom configuration to the server block
    serverSnippet: ""
    # -- Allows appending custom configuration to the http block
    httpSnippet: ""
    # -- Config file contents for Nginx. Passed through the `tpl` function to allow templating
    # @default -- See values.yaml
    file: |
      worker_processes  5;  ## Default: 1
      error_log  /dev/stderr;
      pid        /tmp/nginx.pid;
      worker_rlimit_nofile 8192;

      events {
        worker_connections  4096;  ## Default: 1024
      }

      http {
        client_body_temp_path /tmp/client_temp;
        proxy_temp_path       /tmp/proxy_temp_path;
        fastcgi_temp_path     /tmp/fastcgi_temp;
        uwsgi_temp_path       /tmp/uwsgi_temp;
        scgi_temp_path        /tmp/scgi_temp;

        default_type application/octet-stream;
        log_format   {{ .Values.nginx.nginxConfig.logFormat }}

        {{- if .Values.nginx.verboseLogging }}
        access_log   /dev/stderr  main;
        {{- else }}

        map $status $loggable {
          ~^[23]  0;
          default 1;
        }
        access_log   /dev/stderr  main  if=$loggable;
        {{- end }}

        sendfile     on;
        tcp_nopush   on;
        resolver {{ .Values.global.dnsService }}.{{ .Values.global.dnsNamespace }}.svc.{{ .Values.global.clusterDomain }};

        {{- with .Values.nginx.nginxConfig.httpSnippet }}
        {{ . | nindent 2 }}
        {{- end }}

        # Ensure that X-Scope-OrgID is always present, default to "anonymous" for backwards compatibility when multi-tenancy was turned off.
        map $http_x_scope_orgid $ensured_x_scope_orgid {
          default $http_x_scope_orgid;
          "" "anonymous";
        }

        server {
          listen 8080;

          {{- if .Values.nginx.basicAuth.enabled }}
          auth_basic           "Mimir";
          auth_basic_user_file /etc/nginx/secrets/.htpasswd;
          {{- end }}

          location = / {
            return 200 'OK';
            auth_basic off;
          }

          proxy_set_header X-Scope-OrgID $ensured_x_scope_orgid;

          # Distributor endpoints
          location /distributor {
            proxy_pass      http://{{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /api/v1/push {
            proxy_pass      http://{{ template "mimir.fullname" . }}-distributor-headless.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Alertmanager endpoints
          location {{ template "mimir.alertmanagerHttpPrefix" . }} {
            proxy_pass      http://{{ template "mimir.fullname" . }}-alertmanager.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /multitenant_alertmanager/status {
            proxy_pass      http://{{ template "mimir.fullname" . }}-alertmanager.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /api/v1/alerts {
            proxy_pass      http://{{ template "mimir.fullname" . }}-alertmanager.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Ruler endpoints
          location {{ template "mimir.prometheusHttpPrefix" . }}/config/v1/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          location /api/v1/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location {{ template "mimir.prometheusHttpPrefix" . }}/api/v1/alerts {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location {{ template "mimir.prometheusHttpPrefix" . }}/rules {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }
          location = /ruler/ring {
            proxy_pass      http://{{ template "mimir.fullname" . }}-ruler.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Rest of {{ template "mimir.prometheusHttpPrefix" . }} goes to the query frontend
          location {{ template "mimir.prometheusHttpPrefix" . }} {
            proxy_pass      http://{{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          # Buildinfo endpoint can go to any component
          location = /api/v1/status/buildinfo {
            proxy_pass      http://{{ template "mimir.fullname" . }}-query-frontend.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}:{{ include "mimir.serverHttpListenPort" . }}$request_uri;
          }

          {{- with .Values.nginx.nginxConfig.serverSnippet }}
          {{ . | nindent 4 }}
          {{- end }}
        }
      }

##############################################################################
# The values in and after the `enterprise:` key configure the enterprise features
enterprise:
  # Enable enterprise features. License must be provided, nginx gateway is not installed, instead
  # the enterprise gateway is used.
  enabled: false

  # Whether to generate pre-2.0 Grafana Enterprise Metrics resource labels and selectors, or generate new Kubernetes standard selectors.
  # Rolling upgrade from version 1.7.x without downtime requires this setting to be true. Fresh installation or upgrade with downtime can set
  # it to false.
  legacyLabels: false

  # Container image settings for enterprise, note that pullPolicy and pullSecrets are set in top level .image
  image:
    repository: grafana/enterprise-metrics
    tag: r191-708e13a1

# In order to use Grafana Enterprise Metrics features, you will need to provide the contents of your Grafana Enterprise Metrics
# license, either by providing the contents of the license.jwt, or the name Kubernetes Secret that contains your license.jwt.
# To set the license contents, use the flag `--set-file 'license.contents=./license.jwt'`
# To use your own Kubernetes Secret, `--set license.external=true`.
license:
  contents: "NOTAVALIDLICENSE"
  external: false
  secretName: '{{ include "mimir.resourceName" (dict "ctx" . "component" "license") }}'

# Settings for the initial admin(istrator) token generator job. Can only be enabled if
# enterprise.enabled is true - requires license.
tokengenJob:
  enable: true
  extraArgs: {}
  env: []
  extraEnvFrom: []
  annotations: {}
  initContainers: []

# Settings for the admin_api service providing authentication and authorization service.
# Can only be enabled if enterprise.enabled is true - requires license.
admin_api:
  replicas: 1

  annotations: {}
  service:
    annotations: {}
    labels: {}

  initContainers: []

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  podLabels: {}
  podAnnotations: {}

  nodeSelector: {}
  affinity: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  securityContext: {}

  # -- The SecurityContext for admin_api containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  extraArgs: {}

  persistence:
    subPath:

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  resources:
    requests:
      cpu: 10m
      memory: 32Mi

  terminationGracePeriodSeconds: 60

  tolerations: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

# Settings for the gateway service providing authentication and authorization via the admin_api.
# Can only be enabled if enterprise.enabled is true - requires license.
gateway:
  # If you want to use your own proxy URLs, set this to false.
  useDefaultProxyURLs: true
  replicas: 1

  annotations: {}
  service:
    annotations: {}
    labels: {}
    # -- If the port is left undefined, the service will listen on the same port as the pod
    port: null

  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1

  podLabels: {}
  podAnnotations: {}

  # Pod Disruption Budget
  podDisruptionBudget: {}

  nodeSelector: {}
  affinity: {}

  securityContext: {}

   # -- The SecurityContext for gateway containers
  containerSecurityContext:
    readOnlyRootFilesystem: true

  initContainers: []

  extraArgs: {}

  persistence:
    subPath:

  readinessProbe:
    httpGet:
      path: /ready
      port: http-metrics
    initialDelaySeconds: 45

  resources:
    requests:
      cpu: 10m
      memory: 32Mi

  terminationGracePeriodSeconds: 60

  tolerations: []
  extraContainers: []
  extraVolumes: []
  extraVolumeMounts: []
  env: []
  extraEnvFrom: []

  # Ingress configuration
  ingress:
    # -- Specifies whether an ingress for the gateway should be created
    enabled: false
    # -- Ingress Class Name. MAY be required for Kubernetes versions >= 1.18
    # ingressClassName: gateway
    # -- Annotations for the gateway ingress
    annotations: {}
    # -- Hosts configuration for the gateway ingress
    hosts:
      - host: gateway.gem.example.com
        paths:
          - path: /
            # -- pathType (e.g. ImplementationSpecific, Prefix, .. etc.) might also be required by some Ingress Controllers
            # pathType: Prefix
    # -- TLS configuration for the gateway ingress
    tls:
      - secretName: gem-gateway-tls
        hosts:
          - gateway.gem.example.com

# Settings for the smoke-test job.
smoke_test:
  image:
    repository: grafana/mimir-continuous-test
    # TODO: replace with weekly tag starting with r191
    tag: helm-smoke-test-d12276bfc
    pullPolicy: IfNotPresent
  tenantId: ''
  extraArgs: {}
  env: []
  extraEnvFrom: []
  annotations: {}
  initContainers: []
